environment:
  objective: "The training strategy model can generate corresponding strategies based on historical dialogues and reward scores, so that the attack model can receive new dialogues generated by the strategies, and the generated dialogues can have hierarchical progression to achieve the initial goal"
model:
  obs_dim: 160
  action_dim: 5
  hidden_dim: 128
  lr: 0.00030
ppo:
  clip_epsilon: 0.2
  gamma: 0.99
  lam: 0.95
  epochs: 4
  batch_size: 16
  entropy_coef: 0.01
  value_coef: 0.5
  max_grad_norm: 1.0
training:
  num_episodes: 5
  max_turns: 20
  save_every: 10
logging:
  log_dir: "outputs/logs"
  checkpoint_dir: "outputs/checkpoints"
  dialogue_dir: "outputs/dialogues3"
  use_tensorboard: true

model:
  obs_dim: 32
  seq_len: 5
  action_dim: 18   # 必须等于 TEMPLATE_BANK 的条目数
  hidden_dim: 128
  num_layers: 2
  num_heads: 4
  lr: 1.0e-4
  attack:
    model_name: gpt-4o
    simulated: false
    base_url: "https://poloai.top/v1"
    api_key: "sk-baPtXZhTJf4sFTIsNUYj4u4gBqxCneKndiERYFeFXy4mxAhF"
  target:
    name: gpt-4o
    simulated: false
    mode: mixed
  judge:
    name: gpt-4o-mini
    simulated: false

data:
  root_dir: "test-image"

attack:
    model_name: gpt-4o
    simulated: false
    base_url: "https://poloai.top/v1"
    api_key: "sk-baPtXZhTJf4sFTIsNUYj4u4gBqxCneKndiERYFeFXy4mxAhF"